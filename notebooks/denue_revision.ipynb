{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DENUE Exploratory Data Analysis notebook\n",
    "\n",
    "[DENUE](http://www.beta.inegi.org.mx/app/mapa/denue/) means Directorio Estadístico Nacional de Unidades Economicas. It is maintained by [INEGI](http://www.inegi.org.mx/), the Mexican Institute of Statistics and Geography.\n",
    "\n",
    "In this notebook we start exploring the data as part of our project to map the creative industries in Mexico\n",
    "\n",
    "## About the data\n",
    "\n",
    "This [methodological note](http://www.beta.inegi.org.mx/app/biblioteca/ficha.html?upc=702825097240) describes the data (in Spanish).\n",
    "\n",
    "DENUE contains information about ~5 million active businesses in Mexico. This includes:\n",
    "\n",
    "* Identification\n",
    "* Location\n",
    "* Sector\n",
    "* Size\n",
    "\n",
    "DENUE’s first edition was published in 2010, with data collected in 2009. Individual entrepreneurs and organisations are legally required to register in DENUE and update their information. Other parts of the public sector are also required to provide INEGI with data to maintain DENUE. \n",
    "\n",
    "**Data updates**\n",
    "\n",
    "* Information about larger businesses (>20 employees / $20m in turnover or activities in more than one State) as well as those in some sectors are updated yearly with administrative data and business surveys.\n",
    "\n",
    "* Information about micro/small/medium businesses is partially updated through administrative registers.\n",
    "\n",
    "* Users update their information online continuously, and this information is quality assured by INEGI.\n",
    "\n",
    "* All data in DENUE are updated every 5 years through information produced by the economic census. The latest complete update of DENUE was in 2016, using data from the 2014 economic census.\n",
    "\n",
    "### Conceptual framework and coverage\n",
    "\n",
    "**Unit of analysis**\n",
    "\n",
    "DENUE contains information about establishments (local units) and enterprises. \n",
    "\n",
    "**Sector**\n",
    "\n",
    "DENUE contains information about all industries with the exception of agriculture, farming and forestry, transport, political organisations, domestic workers and extraterritorial units.\n",
    "\n",
    "Industrial activities are classified according to 2013 NAICS. The first edition of DENUE using 2013 NAICs was in 2015 (*this means we can probably use definitions of the creative industries implemented by Nesta in its analysis of the creative industries in North America*)\n",
    "\n",
    "**Period**\n",
    "\n",
    "The period covered by business data depends on the year of incorporation.\n",
    "  * For businesses incorporated before 2014, DENUE data refers to 2014\n",
    "  * For businesses incorporated Jan 2015- Oct 2016 - DENUE data refers to 2015\n",
    "  * For business incorporated Mar 2017-Nov 2017 - Data refers to 2016\n",
    "\n",
    "**Geography**\n",
    "\n",
    "DENUE includes economic units in locations with 2500+ inhabitants as well as ‘economic locations’ such as industrial parks. It doesn’t contain economic units in rural areas./\n",
    "\n",
    "Data are available at the following levels of resolution:\n",
    "* AGEE (States) - 2 digit based on State name. Administrative boundary\n",
    "* AGEM (towns / cities) - 3 digits.\n",
    "* AGEB (micro-geography):\n",
    "  * Urban: 1-50 squares\n",
    "  * Rural: ~11m Ha.\n",
    "\n",
    "Longitude and Latitude data are also available. \n",
    "\n",
    "### Variables\n",
    "\n",
    "* Nombre: Name. Some organisations have generic names.\n",
    "* Denominación o razón social y tipo de sociedad: Type of organisation\n",
    "* Código: industrial code based on NAICs (organisations are allocated to the sector which generates most turnover for the company)\n",
    "* Personal: 8 sizebands (0-251+)\n",
    "* Tipo de Unidad económica: \n",
    "  * Whether the organisation is a subsidiary, and the type of establishment.\n",
    "* Datos de ubicación: Location (address)\n",
    "* Area geográfica: (see above)\n",
    "* Contact details:\n",
    "  * Telephone\n",
    "  * Web address\n",
    "  * Email\n",
    "\n",
    "\n",
    "\n",
    "## Some processing activities\n",
    "\n",
    "* Load data\n",
    "* Merge with creative NAICs codes\n",
    "* Produce some descriptive analysis: creative sectors by location (totals, specialisation)\n",
    "* Analyse access to contact details\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "This includes:\n",
    "\n",
    "* Package imports\n",
    "* Paths\n",
    "* Functions and classes used below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import re\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "today_str = \"_\".join([str(x) for x in [today.day,today.month,today.year]])\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "denue_dir = os.path.join(parent_dir, 'data', 'denue')\n",
    "nesta_dir = os.path.join(parent_dir, 'data', 'nesta') \n",
    "processed_dir = os.path.join(parent_dir, 'data', 'processed')\n",
    "shapefile_dir = os.path.join(parent_dir, 'data', 'shapefiles') \n",
    "reports_dir = os.path.join(parent_dir, 'reports')\n",
    "fig_dir = os.path.join(parent_dir, 'reports', 'figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_11_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_21_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_22_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_23_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_31-33_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_43_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_46111_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_46112-46311_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_46321-46531_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_46591-46911_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_48-49_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_51_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_52_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_53_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_54_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_55_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_56_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_61_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_62_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_71_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_72_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_81_csv.zip\n",
      "https://www.inegi.org.mx/contenidos/masiva/denue/denue_00_93_csv.zip\n"
     ]
    }
   ],
   "source": [
    "denue_listado = open(os.path.join(os.getcwd(), 'DescargaMasivaOD.xml'), 'r')\n",
    "parsed = BeautifulSoup(denue_listado, \"xml\")\n",
    "urls = [x.text for x in parsed.find_all('Archivo')]\n",
    "files_dl = [x for x in urls if re.search(r'denue_00_[0-9\\-]+_csv', x)]\n",
    "for f in files_dl:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/enrique/Documents/mexico_ci_mapping/data/denue/denue_00_11_csv.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-082ab770bf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mzf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenue_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{url} descargado en {denue_dir}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/enrique/Documents/mexico_ci_mapping/data/denue/denue_00_11_csv.zip'"
     ]
    }
   ],
   "source": [
    "for url in files_dl:\n",
    "    dl = requests.get(url)\n",
    "    zf = zipfile.ZipFile(io.BytesIO(dl.content))\n",
    "    with open(os.path.join(denue_dir, url.split('/')[6]), 'wb') as outfile:\n",
    "        outfile.write(dl.content)\n",
    "    print(f'{url} descargado en {denue_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "\n",
    "Here we will process all relevant DENUE files. There are quite a few of them and they are big. To deal with this I will write a class that loads them one at a time, unzips them, extracts companies in creative sectors (based on a lookup table based on NAICS codes) and generates some sector / area reports to normalise findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Load metadata\n",
    "\n",
    "Lookup between NAICs and creative industries codes based on Nesta 2016 (see Table A10 in /references folder)\n",
    "\n",
    "Some of the codes in that table are too coarse (ie advertising also includes management consultancy). We have created a more refined classification that removes some of the non-creative subcodes, but we will generally work with Nesta's classification for consistency. It would be easy to replicate the analysis focusing on the refined categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a file with NAICs codes\n",
    "naics_creative_lookup = pd.read_csv(os.path.join(nesta_dir, \"naics_creative_short.csv\"))\n",
    "naics_creative_lookup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load shapefiles for mapping. We downloaded them from [here](http://www.inegi.org.mx/geo/contenidos/geoestadistica/m_geoestadistico.aspx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estados = gp.read_file(os.path.join(shapefile_dir, \"mexico\"))\n",
    "\n",
    "#They were easy to load. We can use them below\n",
    "estados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estados.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Load one file for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates the file. We will load one that has creative sectors in it\n",
    "zf = zipfile.ZipFile(os.path.join(denue_dir, 'denue_00_51_csv.zip'))\n",
    "\n",
    "#Extract the names\n",
    "zf_names = zf.infolist()\n",
    "\n",
    "for f in zf_names:\n",
    "    print(f.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denue data dictionary\n",
    "\n",
    "#This gets the filename for the data dictionary\n",
    "data_dict_filename = zf_names[0].filename\n",
    "\n",
    "#And we read it\n",
    "denue_dictionary = pd.read_csv(zf.open(data_dict_filename), encoding='latin-1')\n",
    "\n",
    "#We save it so we can have a look at it, and maybe create cleaner names and variables\n",
    "denue_dictionary.to_csv(os.path.join(processed_dir, '{date}_denue_data_dictionary.csv'.format(date=today_str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are interested in the 'denue_inegi_51_.csv' file, index=1\n",
    "denue_data = zf_names[1]\n",
    "\n",
    "#We get its name (which we will use to open the data)\n",
    "denue_file_name = denue_data.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas can read this easily\n",
    "denue_51 = pd.read_csv(zf.open(denue_file_name), encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Here it is\n",
    "denue_51.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It contains 19K observations and 41 variables\n",
    "denue_51.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the top 10 sectors\n",
    "denue_51.nombre_act.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What do the sector codes look like? Can we find them in the NAICs lookups\n",
    "\n",
    "list(set(denue_51.codigo_act))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They have 7 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check lookup. We do this by dropping duplicate codes in the data\n",
    "code_name_lu = denue_51[['codigo_act','nombre_act']].drop_duplicates('codigo_act').reset_index(drop=True)\n",
    "\n",
    "#We have compared the codes in the data with the codes in the NAICs file and they match.\n",
    "#We will work with the NAICs file, enriched with the codes from Nesta (2016) report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denue_51.telefono"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge DENUE and lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's match this with the metadata to see what we get\n",
    "denue_51_creative = pd.merge(denue_51,naics_creative_lookup,left_on='codigo_act',\n",
    "                            right_on='code_int',how='left')\n",
    "\n",
    "#Look at software companies\n",
    "denue_51_creative.loc[denue_51_creative.creative_sector=='software',:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creative sectors in the data\n",
    "denue_51_creative.creative_sector.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sizes\n",
    "pd.crosstab(denue_51_creative.per_ocu,denue_51_creative.creative_sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#States\n",
    "pd.crosstab(denue_51_creative.entidad,denue_51_creative.creative_sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Municipios\n",
    "pd.crosstab(denue_51_creative.municipio,denue_51_creative.creative_sector)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Load all data\n",
    "\n",
    "**Plan**\n",
    "\n",
    "I will write a class that takes a file name, reads it, extracts all creative businesses and also the distribution of companies in all other areas, as well as their size distribution (which we can use to normalise the data)\n",
    "\n",
    "This involves:\n",
    "\n",
    "1. Creating a list of all filenames I want to load\n",
    "2. Writing a class with: \n",
    " * A read method to read the CSV and rename the variables to something tidier\n",
    " * A get_creative method that merges the file with naics_creative lookup and returns all matches\n",
    " * An area_stats method that generates company counts by state and municipio\n",
    "3. Implementing the class while I go for a run :-)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadProcessDenue():\n",
    "    \n",
    "    '''\n",
    "    DenueProcess is a class that takes a filename for a zip file and:\n",
    "   \n",
    "    -Extracts the csv content (read method)\n",
    "    -Cleans variable names (process method)\n",
    "    -Merges with the NAICS Lookup (get_creative method)\n",
    "    -Generates area counts for all sectors (area_counts method).\n",
    "    \n",
    "    It stores the outputs in a creative_businesses attribute, a state_counts attribute and a local_counts \n",
    "    attribute. \n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,filepath):\n",
    "        '''\n",
    "        Initialise the class with a filepath\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.filepath = filepath\n",
    "        \n",
    "    def read_file(self):\n",
    "        '''\n",
    "        Read the csv\n",
    "        \n",
    "        '''\n",
    "        #Get the filepath\n",
    "        filepath = self.filepath\n",
    "        \n",
    "        #Read the zipfile\n",
    "        zf = zipfile.ZipFile(filepath)\n",
    "        \n",
    "        #Get the name of the datafile\n",
    "        data_file_name = zf.infolist()[1].filename\n",
    "        \n",
    "        #Read the file\n",
    "        denue_data = pd.read_csv(zf.open(data_file_name), encoding='latin-1')\n",
    "        \n",
    "        #Assign the denue data to the denue_data attribute\n",
    "        self.denue_data = denue_data\n",
    "\n",
    "    \n",
    "    def get_creative(self):\n",
    "        '''\n",
    "        Extracts creative companies\n",
    "        \n",
    "        '''\n",
    "        #Read all denue data\n",
    "        all_denue = self.denue_data\n",
    "        \n",
    "        #Merge with the creative lookup\n",
    "        creative_denue = pd.merge(all_denue,naics_creative_lookup,\n",
    "                                  left_on='codigo_act',right_on='code_int',how='inner').reset_index(drop=True)\n",
    "        \n",
    "        #Convert the telephone number to a string\n",
    "        #NB the if else is to deal with missing values in the telefone field\n",
    "        #creative_denue['telefono'] = [str(int(x)) if type(x)!=float else np.nan for x in creative_denue['telefono']]\n",
    "        \n",
    "        \n",
    "        #We will store two versions: a complete file and a short file with less variables of interest\n",
    "        \n",
    "        #Complete version with somewhat messy variable names\n",
    "        self.denue_creative_long = creative_denue\n",
    "        \n",
    "        #Also store the tidy version\n",
    "        #NB we need to re-concatenate it with the sector info we merged above\n",
    "        self.denue_creative_short = pd.concat([tidy_denue_data(creative_denue),\n",
    "                                               creative_denue[['creative_nesta_2016','creative_refined',\n",
    "                                                               'creative_sector','has_creative']]],axis=1)\n",
    "                                               \n",
    "        \n",
    "        \n",
    "                                               \n",
    "    def get_context_stats(self):\n",
    "        '''\n",
    "        This extracts contextual information that we will use to compare and normalise the creative data.\n",
    "        \n",
    "        NB this is only preliminary. I assume we will want to do more finely grained comparisons. We\n",
    "        can modify this method to extract what we need to do that.\n",
    "        \n",
    "        For now we will get:\n",
    "        -State counts\n",
    "        -Municipio counts\n",
    "        -Sizeband counts\n",
    "        -Sizeband by state and municipality counts\n",
    "        -Incorporation date counts\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Load all denue data\n",
    "        all_denue = self.denue_data\n",
    "        \n",
    "        #Extract contextual reports with a function\n",
    "        self.context_stats = get_context(all_denue)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_denue_data(denue_data):\n",
    "    '''\n",
    "    This function returns a clean denue file with a few relevant variables\n",
    "    We will use this for economic analysis\n",
    "    NB the variables we are removing will nevertheless be important for marketing\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    interesting_vars = ['id','nom_estab','raz_social','codigo_act','nombre_act','per_ocu',\n",
    "                       'cod_postal','entidad','municipio','localidad','telefono','correoelec','www',\n",
    "                       'tipoUniEco','latitud','longitud','fecha_alta']\n",
    "    \n",
    "    tidy_name_vars = ['id','name','legal_name','sector','sector_description','employee_sizeband',\n",
    "                      'postcode','state','municipality','location','telephone','email','website','type_organisation',\n",
    "                      'lat','lon','incorp_date']\n",
    "    \n",
    "    denue_selected = denue_data[interesting_vars]\n",
    "    \n",
    "    denue_selected.columns = tidy_name_vars\n",
    "    \n",
    "    return(denue_selected)\n",
    "\n",
    "def get_context(denue_data):\n",
    "    '''\n",
    "    This function extracts some contextual data as part of the get_context_stats method in the ReadProcessDenue\n",
    "    class.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Tidy data (having standard names will help processing later)\n",
    "    tidy_denue = tidy_denue_data(denue_data)\n",
    "    \n",
    "    #Generate a bunch of counts\n",
    "    state_counts, municipality_counts,sizeband_counts,incorp_date_counts = [tidy_denue[x].value_counts() for x in \n",
    "                                                         ['state','municipality',\n",
    "                                                          'employee_sizeband','incorp_date']]\n",
    "    \n",
    "    #And a couple of crosstabs\n",
    "    state_sizeb_crosstabs,municipality_sizeb_crosstabs = [pd.crosstab(tidy_denue[x],\n",
    "                                                                      tidy_denue['employee_sizeband']) for x in\n",
    "                                                         ['state','municipality']]\n",
    "    \n",
    "    #Put everything in a list\n",
    "    out_list = [state_counts,municipality_counts,sizeband_counts,incorp_date_counts,\n",
    "               state_sizeb_crosstabs,municipality_sizeb_crosstabs]\n",
    "    \n",
    "    return(out_list)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's run this\n",
    "\n",
    "#Extract a list of files in the 'sector data' directory\n",
    "all_sector_files = os.listdir(denue_dir)\n",
    "sector_files_csv = [x for x in all_sector_files if 'csv' in x]\n",
    "\n",
    "\n",
    "#This is a container list where we will put the info we are interested in for now (the tidy denue data and the \n",
    "# contextual data\n",
    "\n",
    "denue_eda_outputs = []\n",
    "\n",
    "\n",
    "#We'll run it as an old school loop\n",
    "for dataset in sector_files_csv:\n",
    "    \n",
    "    #For each dataset...\n",
    "    #We print it to keep track of things\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    #Create the path\n",
    "    input_file_path = os.path.join(denue_dir, dataset)\n",
    "    \n",
    "    #Initialise the class\n",
    "    denue_object = ReadProcessDenue(input_file_path)\n",
    "    \n",
    "    #Read the data\n",
    "    denue_object.read_file()\n",
    "    \n",
    "    #Get the creative data\n",
    "    denue_object.get_creative()\n",
    "    \n",
    "    #Get the contextual data\n",
    "    denue_object.get_context_stats()\n",
    "    \n",
    "    #Put everything in a list\n",
    "    outputs_of_interest = [denue_object.denue_creative_short,denue_object.denue_creative_long,\n",
    "                          denue_object.context_stats]\n",
    "    \n",
    "    #Append to DENUE\n",
    "    denue_eda_outputs.append(outputs_of_interest) \n",
    "    \n",
    "    \n",
    "\n",
    "#I'm ignoring the warnings although eventually I will fix the code to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This concatenates all the creative companies into a single dataframe\n",
    "creative_tidy = pd.concat([x[0] for x in denue_eda_outputs]).reset_index(drop=True)\n",
    "creative_tidy.to_csv(os.path.join(processed_dir, '{today}_denue_creative.csv'.format(today=today_str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore data\n",
    "\n",
    "Where we explore the DENUE data we have downloaded. \n",
    "\n",
    "The exploration has 2 angles:\n",
    "\n",
    "* Descriptives\n",
    "  * Sectoral distribution\n",
    "  * Geography of the sector (including maps and specialisation)\n",
    "  * Incorporation dates ('age'?)\n",
    "* Comparative analysis\n",
    "  * Compare CI sizebands with rest of the economy or other sectors\n",
    "  * Compare CI incorporation dates with rest of the economy or other sectors\n",
    "* Availability of contact details\n",
    "  * This will inform the survey design and implementation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sectoral distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many creative businesses are there in Mexico, and in what sectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the Nesta NAICS definition\n",
    "nesta_2016_def = creative_tidy.loc[creative_tidy.creative_nesta_2016==1,:]\n",
    "\n",
    "nesta_ref = creative_tidy.loc[creative_tidy.creative_refined==1,:]\n",
    "\n",
    "print(\"According to the Nesta 2016 NAICs definition there are {num} creative business in Mexico\".\n",
    "      format(num=len(nesta_2016_def)))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"According to the refined definition there are {num} creative business in Mexico\".\n",
    "      format(num=len(nesta_ref)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do they have unique ids? \n",
    "\n",
    "#Yes. We should in any case check their legal status\n",
    "len(set(nesta_2016_def.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What percentage of the total does this represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nesta_2016_def.loc[nesta_2016_def.website.isna()==False,:][\n",
    "    ['id','name','creative_sector','employee_sizeband','website']].to_csv(\n",
    "    os.path.join(processed_dir,'denue_website_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_businesses_denue = np.sum([x[2][0].sum() for x in denue_eda_outputs])\n",
    "\n",
    "#Percentage of creative businesses in DENUE\n",
    "100*90004/total_businesses_denue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare both:\n",
    "\n",
    "#We create a table that concatenates both sectors\n",
    "creative_comp_table = pd.concat([nesta_2016_def['creative_sector'].value_counts(),\n",
    "                                nesta_ref['creative_sector'].value_counts()],axis=1,sort=True)\n",
    "\n",
    "#Rename columns\n",
    "creative_comp_table.columns=['creative_nesta_2016','creative_refined_def']\n",
    "\n",
    "#Sort values\n",
    "creative_comp_table.sort_values('creative_nesta_2016',ascending=False,inplace=True)\n",
    "\n",
    "#We extract the index of the table to sort charts later\n",
    "sectors_sorted = creative_comp_table.index\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "creative_comp_table.plot.bar(ax=ax)\n",
    "\n",
    "\n",
    "ax.set_yticklabels(ax.get_yticks(),size=14)\n",
    "ax.set_xticklabels(labels=creative_comp_table.index,size=16,rotation=45,ha='right')\n",
    "ax.legend(fontsize=14)\n",
    "ax.set_title('Number of creative businesses in DENUE according to different definitions',fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_sector_bar_chart.pdf'.format(date=today_str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the `naics_creative_lookup_short` file we can see what explains the differences:\n",
    "\n",
    "* Music and performing arts in Nesta 2016 includes many generic and sports related educational activities\n",
    "* Advertising and marketing in Nesta 2016 includes management consulting activities\n",
    "* Architecture in Nesta 2016 includes engineering and drafting services, building inspection and other things unrelated to architectural design\n",
    "* Crafts in Nesta 2016 doesn't include several activities related to jewelry and metalwork\n",
    "\n",
    "As mentioned before, we will focus on the Nesta definition for now. We can change the definition later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many people work in the sector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We call them cis for creative industries\n",
    "cis = nesta_2016_def.copy()\n",
    "\n",
    "#Make estado lowercase to match with the map data later\n",
    "cis['state'] = [x.lower().strip() for x in cis['state']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the size distribution\n",
    "\n",
    "size_distribution = pd.DataFrame(cis['employee_sizeband'].value_counts())\n",
    "size_distribution['share_pc'] = size_distribution/size_distribution.sum()\n",
    "\n",
    "sizeb_sorted = size_distribution.index\n",
    "\n",
    "size_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sizeband by creative subsector compared with the creative industries overall and other sectors\n",
    "\n",
    "sector_size = pd.crosstab(cis['creative_sector'],cis['employee_sizeband'],normalize=0)\n",
    "\n",
    "\n",
    "#Now we combine with the size distribution chart above and with a size distribution table *for all companies*\n",
    "\n",
    "#This creates a sizeband distribution for all businesses in DENUE\n",
    "sizeband_distr_all= pd.concat([x[2][2] for x in denue_eda_outputs],axis=1,sort=True).sum(axis=1)\n",
    "\n",
    "#We calculate shares\n",
    "sizeband_distr_shares = sizeband_distr_all/sizeband_distr_all.sum()\n",
    "\n",
    "#Concatenate everything\n",
    "sector_size_all = pd.concat([sector_size.T,size_distribution['share_pc'],sizeband_distr_shares],axis=1,sort=True)\n",
    "\n",
    "#We rename the columns for all creative and other sectors\n",
    "sector_size_all.rename(columns={'share_pc':'creative_industries',0:'all_sectors'},inplace=True)\n",
    "\n",
    "#We want to show all creative subsectors first, sorted by their size. \n",
    "\n",
    "\n",
    "sectors_sorted = sector_size_all.T.sort_values(['0 a 5 personas'],ascending=True).index\n",
    "\n",
    "#We put creative industries and all sectors at the end. This is what this list comprehension is for\n",
    "sectors_sorted = [x for x in sectors_sorted if x not in ['all_sectors','creative_industries']]+[\n",
    "    'creative_industries','all_sectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12.5,8))\n",
    "\n",
    "sector_size_all.T.loc[sectors_sorted,sizeb_sorted].plot.bar(stacked=True,ax=ax,width=0.75,\n",
    "                                                      title='Size distribution by sector')\n",
    "\n",
    "#We adjust limits to fit the legend on the right\n",
    "ax.set_xlim((-0.5,14))\n",
    "\n",
    "ax.set_yticklabels(ax.get_yticks(),size=14)\n",
    "ax.set_xticklabels(labels=sectors_sorted,size=14,rotation=45,ha='right')\n",
    "ax.legend(fontsize=14)\n",
    "ax.set_title('Sector sizeband distribution',fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_size_distribution.pdf'.format(date=today_str)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a midpoint estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midpoint(sizeband_value):\n",
    "    '''\n",
    "    This function extracts a midpoint estimate from the sizeand variable in the DENUE data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #With the exception of '251 y mas...' the categories say 'x to y' people. We will split on whitespace\n",
    "    #and extract the values,turn them into integers and average them.\n",
    "    \n",
    "    #We assume that the top value is 251. Maybe we could survey these companies to get their employment. Who are they?\n",
    "    \n",
    "    if '251' in sizeband_value:\n",
    "        estimate = 251\n",
    "        \n",
    "    else:\n",
    "        #Split\n",
    "        split = sizeband_value.split(\" \")\n",
    "\n",
    "        #Get mean\n",
    "        estimate = np.mean([int(split[0]),int(split[2])])\n",
    "        \n",
    "    return(estimate)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here it is\n",
    "cis['employment_estimate'] = [get_midpoint(x) for x in cis.employee_sizeband]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis.employment_estimate.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number is significantly lower than what other people say, eg '2m jobs including 'direct and indirect' jobs' according to [this blog](https://www.forbes.com.mx/la-cultura-riqueza-mal-vista/) (Note that it includes no definition). Note that the right-censoring of the data means that we are probably underestimating the size of the companies in DENUE (for example, according to [Wikipedia](https://es.wikipedia.org/wiki/Televisa), Televisa employs 15,000 people but these data would estimate its employmnent at 11.\n",
    "\n",
    "Maybe we could run the bigger companies vs Wikipedia to extract their employment? What are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_company_list = list(cis.loc[cis.employment_estimate>250,'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_company_list[:10]\n",
    "\n",
    "#There is some repetition in the names. Are these different organisations or duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sector size estimates\n",
    "sector_size_estimates = cis.groupby('creative_sector')['employment_estimate'].sum().sort_values(ascending=False)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "sector_size_estimates.plot.bar(ax=ax,color='orange',title='Sector size estimates')\n",
    "\n",
    "\n",
    "ax.set_yticklabels(ax.get_yticks(),size=14)\n",
    "ax.set_xticklabels(labels=creative_comp_table.index,size=14,rotation=45,ha='right')\n",
    "ax.legend(fontsize=14)\n",
    "ax.set_title('Sector size estimates',fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_size_estimates.pdf'.format(date=today_str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing employment in CIs with other industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will concatenate business counts in different sizebands for each sector outside of the CIs\n",
    "\n",
    "all_sizebands = pd.concat([x[2][2] for x in denue_eda_outputs],axis=1,sort=True).sum(axis=1).reset_index(drop=False)\n",
    "\n",
    "#We produce the 'midpoint estimate' of the data \n",
    "all_sizebands['midpoint'] = [get_midpoint(x) for x in all_sizebands['index']]\n",
    "\n",
    "#All employment multiplies the midpoint estimate by the number of companies in each sizeband\n",
    "all_employment = np.sum(all_sizebands['midpoint']*all_sizebands[0])\n",
    "\n",
    "#We divide the creative employment by all employment to get an estimate\n",
    "\n",
    "np.round(100*699838.0/all_employment,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5% of all estimated employment is in the creative industries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other inter-sectoral comparisons\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incorporation dates\n",
    "\n",
    "Date when different organisations joined the register. This isn't the same as company age.\n",
    "\n",
    "We will look at this by subsector and compared to the creative industries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many incorporation values are there?\n",
    "\n",
    "cis_join_date = cis.incorp_date.value_counts()\n",
    "\n",
    "cis_join_date.name='creative_industries'\n",
    "\n",
    "cis_subsector_join_date = pd.crosstab(cis.incorp_date,cis.creative_sector)\n",
    "\n",
    "#How do they compare with the data for all other sectors?\n",
    "#As previously, we extract the information from the denue outputs container and sum to\n",
    "#get total number of companies by date of incorporation into the register \n",
    "\n",
    "all_join_date = pd.concat([x[2][3] for x in denue_eda_outputs],axis=1,sort=True).sum(axis=1)\n",
    "all_join_date.name='all_sectors'\n",
    "\n",
    "\n",
    "#Let's put everything together\n",
    "\n",
    "#We want to sort the dates from the oldest to the newest\n",
    "merged_join_date =pd.concat([cis_subsector_join_date,cis_join_date,all_join_date],axis=1,sort=True).reset_index(drop=False)\n",
    "\n",
    "#Combine inclusion dates by year\n",
    "merged_join_date['year'] = [int(x.split(\"-\")[1]) for x in merged_join_date['index']]\n",
    "\n",
    "#Sum by year and reindex\n",
    "merged_join_date = merged_join_date.drop('index',axis=1).groupby('year').sum().apply(lambda x: x/x.sum(),axis=0)\n",
    "\n",
    "#Sort sectors by 'novelty' (Importance of incorporations in 2014 - 2016) with all_sectors and creative_industries\n",
    "#at the end\n",
    "sectors_sorted_date = merged_join_date.T.iloc[:,-2:].sum(axis=1).sort_values(ascending=False).index\n",
    "\n",
    "sectors_sorted_date = [x for x in sectors_sorted_date if x not in [\n",
    "    'creative_industries','all_sectors']] + ['creative_industries','all_sectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12.5,8))\n",
    "\n",
    "merged_join_date.T.loc[sectors_sorted_date,:].plot.bar(stacked=True,ax=ax,width=0.75,\n",
    "                                                      title='DENUE registering date by sector')\n",
    "\n",
    "#We adjust limits to fit the legend on the right\n",
    "ax.set_xlim((-0.5,12.2))\n",
    "\n",
    "\n",
    "ax.set_yticklabels(ax.get_yticks(),size=14)\n",
    "ax.set_xticklabels(labels=sectors_sorted_date,size=14,rotation=45,ha='right')\n",
    "ax.legend(fontsize=14)\n",
    "ax.set_title('Sector DENUE incorporation distribution',fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_incorp_distribution.pdf'.format(date=today_str)))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, check incorporation dates by size\n",
    "\n",
    "#Crosstab\n",
    "inc_dates_size = pd.crosstab(cis.incorp_date,cis.employee_sizeband,normalize=1).loc[:,sizeb_sorted]\n",
    "\n",
    "#As before, we extract the year from the incorporation variable so we can aggregate and sort more easily\n",
    "inc_dates_size['year'] = [int(x.split(\"-\")[1]) for x in inc_dates_size.index]\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "inc_dates_size.groupby('year').sum().T.plot.bar(stacked=True,ax=ax,width=0.75,\n",
    "                                                      title='DENUE registering date by sizeband (all creative)')\n",
    "\n",
    "#We adjust limits to fit the legend on the right\n",
    "ax.set_xlim((-0.5,7.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is kind of surprising - many larger companies have been added to the data in recent years. Let's check some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis.loc[(['2016' in x for x in cis['incorp_date']]) & (cis.employment_estimate>250),:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the numbers are small (36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where is the sector?\n",
    "\n",
    "We will examine its geography in terms of:\n",
    "* Total levels of activity by state and municipality, and totals by subsector\n",
    "* Values normalised by activity in other industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis.groupby('state')['employment_estimate'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's end the day with a map\n",
    "\n",
    "#Distribution of businesses by state\n",
    "state_creative_counts = cis['state'].value_counts()\n",
    "\n",
    "#Employment estimates\n",
    "state_employment_estimates = cis.groupby('state')['employment_estimate'].sum()\n",
    "\n",
    "#Combine business and employment estimates\n",
    "state_all_creative = pd.concat([state_creative_counts,state_employment_estimates],axis=1,sort=True)\n",
    "\n",
    "#Remember we loaded the estado shapefile before. We make the estate name lowercases to merge on them\n",
    "estados['ESTADO'] = [x.lower().strip() for x in estados['ESTADO']]\n",
    "\n",
    "#They also use different names for Mexico City (DENUE calls it distrito federal and \n",
    "#the shapefiles call it Ciudad de Mexico. \n",
    "#We fix hackily\n",
    "\n",
    "# Shapefile state names need to coincide with denues names.\n",
    "estados['ESTADO'] = ['michoacán de ocampo' if x =='michoacán' else x for x in estados['ESTADO']]\n",
    "estados['ESTADO'] = ['veracruz de ignacio de la llave' if x =='veracruz' else x for x in estados['ESTADO']]\n",
    "estados['ESTADO'] = ['ciudad de méxico' if x =='distrito federal' else x for x in estados['ESTADO']]\n",
    "estados['ESTADO'] = ['coahuila de zaragoza' if x =='coahuila' else x for x in estados['ESTADO']]\n",
    "\n",
    "#Merge them\n",
    "state_creative_polys = pd.merge(estados,state_all_creative.reset_index(drop=False),left_on='ESTADO',\n",
    "                               right_on='index')\n",
    "\n",
    "state_all_creative\n",
    "estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(13,7))\n",
    "\n",
    "#Plot business counts\n",
    "state_creative_polys.plot('state',ax=ax,cmap='viridis',legend=True)\n",
    "\n",
    "ax.set_title('Number of creative businesses by state',size=16)\n",
    "\n",
    "#Set axis off\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{today}_total_business_map.png'.format(today=today_str)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(13,7))\n",
    "\n",
    "#Plot business counts\n",
    "state_creative_polys.plot('employment_estimate',ax=ax,cmap='viridis',legend=True)\n",
    "\n",
    "ax.set_title('Creative employment level by state',size=16)\n",
    "\n",
    "#Set axis off\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{today}_employment_estimate_map.png'.format(today=today_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What share do the top 5 locations represent for creative business counts and employment\n",
    "print(state_creative_counts.sort_values(ascending=False)[:5]/state_creative_counts.sum())\n",
    "print(state_employment_estimates.sort_values(ascending=False)[:5]/state_employment_estimates.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a chart that measures the levels of concentration in different creative sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We could probably put this function in the previous class to keep things tidy\n",
    "def get_state_employment_estimates(df):\n",
    "    '''\n",
    "    This function extracts, for each state-size distribution table,\n",
    "    an estimate of employment based on company sizebands\n",
    "    '''\n",
    "    \n",
    "    #We melt the dataframe to simplify processing\n",
    "    #We need to reset the index to use it as the id var when melting\n",
    "    df_melted = pd.melt(df.reset_index(drop=False),id_vars='state')\n",
    "    \n",
    "    df_melted['midpoint'] = [get_midpoint(x) for x in df_melted['employee_sizeband']]\n",
    "    \n",
    "    #Multiply the midpoint by number of businesses\n",
    "    df_melted['employment_estimate'] = df_melted['midpoint']*df_melted['value']\n",
    "    \n",
    "    #Regroup\n",
    "    df_aggregate = df_melted.groupby('state')['employment_estimate'].sum()\n",
    "    \n",
    "    return(df_aggregate)\n",
    "\n",
    "\n",
    "def lorenz_plot(shares_df,name_for_title,ax=ax):\n",
    "    '''\n",
    "    Function that takes a dataframe with shares of activity by observation and returns \n",
    "    a figure plotting them buy ranking.\n",
    "    \n",
    "    '''\n",
    "    #Loops over every column, sorts it and plots it. We play with colours to highlight creative\n",
    "    #and all_sectors\n",
    "    \n",
    "    for x in shares_df.columns:\n",
    "        ax.plot(np.array(shares_df.loc[:,x].sort_values(ascending=False)),\n",
    "                c='red' if x=='all_creative' else 'black' if x=='all_sectors' else sector_map_lookup[x],\n",
    "                linewidth=4 if x=='all_creative' else 4 if x=='all_sectors' else 3,\n",
    "           #alpha=0.9 if x not in ['all_sectors','all_creative'] else 1\n",
    "               )\n",
    "\n",
    "    ax.legend(labels=shares_df.columns,fontsize=14)\n",
    "    ax.set_title(\"{name}:State share of total by state ranking\".format(name=name_for_title),size=16)\n",
    "\n",
    "    ax.set_yticklabels([100*x for x in ax.get_yticks()],size=12)\n",
    "    ax.set_xticks(np.arange(len(shares_df)))\n",
    "    ax.set_xlabel('State position',fontsize=12)  \n",
    "    ax.set_ylabel('% of all {name} activity'.format(name=name_for_title),fontsize=14)  \n",
    "    \n",
    "    return(ax)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Are the creative industries more concentrated than other sectors? We look at this based on \n",
    "\n",
    "\n",
    "# Get sectoral shares, creative shares and total shares\n",
    "creative_subsector_shares = pd.crosstab(cis.state,cis.creative_sector, normalize=1)\n",
    "creative_industries_shares = cis.state.value_counts(normalize=True)\n",
    "creative_industries_shares.name = 'all_creative'\n",
    "\n",
    "#All sectors\n",
    "all_sectors_state_counts = pd.concat([x[2][0] for x in denue_eda_outputs],sort=True).reset_index(\n",
    "    drop=False).groupby('index')['state'].sum()\n",
    "all_sectors_state_shares = all_sectors_state_counts/all_sectors_state_counts.sum()\n",
    "all_sectors_state_shares.index = [x.lower().strip() for x in all_sectors_state_shares.index]\n",
    "all_sectors_state_shares.name = 'all_sectors'\n",
    "\n",
    "#All state shares\n",
    "all_state_shares = pd.concat([creative_subsector_shares,creative_industries_shares,\n",
    "                              all_sectors_state_shares],axis=1,sort=True)\n",
    "\n",
    "#Same thing for employment:\n",
    "#Creative subsector\n",
    "#Create total employment levels, pivot and normalise\n",
    "creative_subsector_empl_shares = pd.pivot_table(\n",
    "    cis.groupby(['state','creative_sector'])['employment_estimate'].sum().reset_index(drop=False),\n",
    "    index='state',columns='creative_sector',values='employment_estimate').apply(lambda x: x/x.sum(),axis=0)\n",
    "\n",
    "#All creative industries\n",
    "all_cis_state_employment = cis.groupby(['state'])['employment_estimate'].sum()\n",
    "all_cis_state_empl_shares = all_cis_state_employment/all_cis_state_employment.sum()\n",
    "\n",
    "all_cis_state_empl_shares.name = 'all_creative'\n",
    "\n",
    "#All economy\n",
    "all_sectors_employment_state = pd.concat(\n",
    "    [get_state_employment_estimates(x[2][4]) for x in denue_eda_outputs],axis=1,sort=True).sum(axis=1)\n",
    "\n",
    "all_sectors_employment_state.index = [x.lower().strip() for x in all_sectors_employment_state.index]\n",
    "\n",
    "#Create shares\n",
    "all_sectors_empl_state_share = all_sectors_employment_state/all_sectors_employment_state.sum()\n",
    "all_sectors_empl_state_share.name = 'all_sectors'\n",
    "\n",
    "all_state_empl_shares = pd.concat([creative_subsector_empl_shares,all_cis_state_empl_shares,\n",
    "                                  all_sectors_empl_state_share],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally: plot\n",
    "\n",
    "#Plot\n",
    "sector_colors = plt.cm.get_cmap('tab20_r').colors[:len(all_state_shares.columns[:-1])]\n",
    "\n",
    "sector_map_lookup = {x:y for x,y in zip(all_state_shares.columns,sector_colors)}\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(17,9),ncols=2,sharey=True)\n",
    "\n",
    "lorenz_plot(all_state_shares,ax=ax[0],name_for_title='Number businesses')\n",
    "lorenz_plot(all_state_empl_shares,ax=ax[1],name_for_title='Employment level')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.suptitle('Concentration of creative businesses / employment by state',y=1.02,size=18)\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_lorenz_states.pdf'.format(date=today_str)),bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "sector_colors = plt.cm.get_cmap('tab20_r').colors[:len(all_state_shares.columns[:-1])]\n",
    "\n",
    "sector_map_lookup = {x:y for x,y in zip(all_state_shares.columns,sector_colors)}\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "for x in all_state_shares.columns:\n",
    "    ax.plot(np.array(all_state_shares.loc[:,x].sort_values(ascending=False)),\n",
    "           c=sector_map_lookup[x] if x!='all_sectors' else 'black',linewidth=3,\n",
    "           alpha=0.9 if x not in ['all_sectors','all_creative'] else 1)\n",
    "\n",
    "ax.legend(labels=all_state_shares.columns)\n",
    "ax.set_title(\"State share of total by state ranking\",size=14)\n",
    "\n",
    "ax.set_yticklabels([100*x for x in ax.get_yticks()],size=12)\n",
    "ax.set_xticks(np.arange(len(all_state_shares)))\n",
    "ax.set_xlabel('State position',size=12)  \n",
    "ax.set_ylabel('% of all activity',size=12)  \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate measures of specialisation\n",
    "\n",
    "#This function calculates LQs\n",
    "\n",
    "#Functions\n",
    "def create_lq_df(df,year=None):\n",
    "    '''\n",
    "    Takes a df with cells = activity in col in row and returns a df with cells = lq\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    area_activity = df.sum(axis=0)\n",
    "    area_shares = area_activity/area_activity.sum()\n",
    "    \n",
    "    lqs = df.apply(lambda x: (x/x.sum())/area_shares, axis=1)\n",
    "    \n",
    "    if year!=None:\n",
    "        lqs['period'] = year\n",
    "    \n",
    "    return(lqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_counts_to_get_lqs(subsector_df,creative_df,all_sectors_df):\n",
    "    '''\n",
    "    This function takes a subsector df, creative df and all sectors df\n",
    "    and operates on them to return a creative LQ df. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    creative_all_state = pd.concat([creative_df,all_sectors_df],axis=1)\n",
    "    creative_all_state.columns=['creative_industries','all_industries']\n",
    "\n",
    "    creative_all_state['not_creative'] =creative_all_state['all_industries'] - creative_all_state['creative_industries']\n",
    "    \n",
    "    \n",
    "    #Now we have everything we need to calculate the LQ\n",
    "    #We use the function we defined above. We combine creative data with \n",
    "    #not creative to normalise over the total in the locality.\n",
    "    #NB we drop not creative at the end because we don't plan to report it.\n",
    "\n",
    "    creative_subsector_state_lq,creative_industries_state_lq = [\n",
    "        create_lq_df(pd.concat([x,creative_all_state['not_creative']],axis=1)).drop('not_creative',axis=1) for\n",
    "        x in [subsector_df,creative_df]]\n",
    "\n",
    "    #Now we combine the subsector and industry data for mapping\n",
    "\n",
    "    creative_state_lq = pd.concat([creative_industries_state_lq,creative_subsector_state_lq],axis=1)\n",
    "\n",
    "    creative_state_lq.rename(columns={0:'all_creative'},inplace=True)\n",
    "\n",
    "    return(creative_state_lq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a wide table with creative company counts by state and creative sector\n",
    "\n",
    "#This simply pivots a grouped df where we counted the number of unique ids in every state-sector combination\n",
    "creative_subsector_state = pd.pivot_table(\n",
    "    cis.groupby(['state','creative_sector'])['id'].count().reset_index(drop=False),\n",
    "    index='state',\n",
    "    columns='creative_sector',values='id')\n",
    "\n",
    "creative_subsector_state.head()\n",
    "\n",
    "#Also calculate the total CIs per state, summing over the rows above\n",
    "creative_industries_state =creative_subsector_state.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now we combine this with the total counts by sector\n",
    "\n",
    "#All state counts\n",
    "#Concatenate and sum the company counts we extracted before\n",
    "all_state = pd.concat([x[2][0] for x in denue_eda_outputs],axis=1,sort=True).sum(axis=1)\n",
    "\n",
    "#Make the index lowercase for merging\n",
    "#We also need to remove trailing whitespaces \n",
    "all_state.index = [x.lower().strip() for x in all_state.index]\n",
    "\n",
    "creative_state_lq = process_counts_to_get_lqs(creative_subsector_state,creative_industries_state,all_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_state_lq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_creative_lqs_polys = pd.merge(estados,creative_state_lq.reset_index(drop=False),left_on='ESTADO',\n",
    "                               right_on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(polygon_df,sector,discretised=False,ax=ax):\n",
    "    '''\n",
    "    This function takes a polygon df and a variable and returns a map. We can ask it to discretise the data\n",
    "    into deciles too. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #If we want to discretise the data we transform the sector variable into deciles\n",
    "    if discretised!=False:\n",
    "        polygon_df[sector]= pd.qcut(polygon_df[sector],q=np.arange(0,1.1,0.1),\n",
    "                                    labels=False,duplicates='drop')\n",
    "        \n",
    "    polygon_df.plot(sector,ax=ax,cmap='bwr',legend=False,edgecolor='black',\n",
    "                                 linewidth=0.5)\n",
    "\n",
    "    ax.set_title('{x}'.format(x=sector),size=16)\n",
    "    \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And then we map\n",
    "#NB We haven't added legends yet - \n",
    "#the graphs are not strictly comparable because the color-scale is set based on the distribution for each variable\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,12),nrows=5,ncols=2)\n",
    "\n",
    "for num,sector in enumerate(creative_state_lq.columns):\n",
    "    \n",
    "    if num<5:\n",
    "        col=0\n",
    "        row=num\n",
    "    else:\n",
    "        col=1\n",
    "        row=num-5\n",
    "    \n",
    "    plot_map(polygon_df=state_creative_lqs_polys,sector=sector,ax=ax[row][col])\n",
    "    \n",
    "fig.suptitle('Creative business specialisation by state',y=1.02,size=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_business_spec_maps.png'.format(date=today_str)),bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do something similar with employment.\n",
    "\n",
    "#Create employment LQs\n",
    "#Get employment estimates by subsector\n",
    "cr_subsector_employment_state = pd.pivot_table(cis.groupby(\n",
    "    ['state','creative_sector'])['employment_estimate'].sum().reset_index(drop=False),\n",
    "                                               index='state',\n",
    "                                               columns='creative_sector',\n",
    "                                               values='employment_estimate')\n",
    "\n",
    "#Get creative industries employment\n",
    "all_creative_employment_state = cr_subsector_employment_state.sum(axis=1)\n",
    "\n",
    "#We would also need to get employment estimates by location\n",
    "all_sectors_employment_state = pd.concat(\n",
    "    [get_state_employment_estimates(x[2][4]) for x in denue_eda_outputs],axis=1,sort=True).sum(axis=1)\n",
    "\n",
    "all_sectors_employment_state.index = [x.lower().strip() for x in all_sectors_employment_state.index]\n",
    "\n",
    "#Same as we did before, using the function to process creative dfs into lqs\n",
    "creative_state_lq_emp =process_counts_to_get_lqs(cr_subsector_employment_state,all_creative_employment_state,\n",
    "                                                all_sectors_employment_state)\n",
    "\n",
    "#And merge with polygons for mapping\n",
    "state_creative_emp_lqs_polys = pd.merge(estados,creative_state_lq_emp.reset_index(drop=False),left_on='ESTADO',\n",
    "                               right_on='state')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And then we map.\n",
    "#Still no legend\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,12),nrows=5,ncols=2)\n",
    "\n",
    "for num,sector in enumerate(creative_state_lq_emp.columns):\n",
    "    \n",
    "    if num<5:\n",
    "        col=0\n",
    "        row=num\n",
    "    else:\n",
    "        col=1\n",
    "        row=num-5\n",
    "    \n",
    "    plot_map(polygon_df=state_creative_emp_lqs_polys,sector=sector,ax=ax[row][col])\n",
    "    \n",
    "fig.suptitle('Creative employment specialisation by state',y=1.02,size=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_empl_spec_maps.png'.format(date=today_str)),bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of concentration in Mexico DF and Nuevo León with some exceptions like Film Radio and TV in the North or Durango and Guerrero in Crafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are discretising each LQ distribution we plot (bin it in its decile)\n",
    "#Colours for states are comparable (everywhere is binned into deciles)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,12),nrows=5,ncols=2)\n",
    "\n",
    "for num,sector in enumerate(creative_state_lq_emp.columns):\n",
    "    \n",
    "    if num<5:\n",
    "        col=0\n",
    "        row=num\n",
    "    else:\n",
    "        col=1\n",
    "        row=num-5\n",
    "    \n",
    "    plot_map(polygon_df=state_creative_emp_lqs_polys,sector=sector,ax=ax[row][col],discretised=True)\n",
    "    \n",
    "fig.suptitle('Creative employment specialisation by state (discretised)',y=1.02,size=18)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting - does this suggest some trans-state clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colocation(lq_df,name_for_title,ax=ax):\n",
    "    '''\n",
    "    Function that creates a co-location heatmap taking a df with LQs by location (state) as input\n",
    "    \n",
    "    '''\n",
    "    #Create the correlation matrix with the input df\n",
    "    correlation_matrix = lq_df.corr()\n",
    "    \n",
    "    #Plot\n",
    "    im = ax.imshow(correlation_matrix,cmap='seismic',aspect='auto')\n",
    "    \n",
    "    #Colorbar\n",
    "    fig.colorbar(im,ax=ax)\n",
    "    \n",
    "    #Axes\n",
    "    ax.set_xticks(np.arange(len(correlation_matrix)))\n",
    "    ax.set_yticks(np.arange(len(correlation_matrix)))\n",
    "    \n",
    "    ax.set_xticklabels(correlation_matrix.index,rotation=45,ha='right',size=14)\n",
    "    ax.set_yticklabels(correlation_matrix.index,size=14)\n",
    "    \n",
    "    ax.set_title('{name} co-location'.format(name=name_for_title),size=14)\n",
    "    return(ax)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,12),nrows=2,sharex=True)\n",
    "\n",
    "sectors_coloc = ['advertising_marketing','design','software','architecture',\n",
    "                 'music_performing_arts','publishing',\n",
    "                 'film_radio_tv','libraries_museums','crafts']\n",
    "\n",
    "\n",
    "plot_colocation(creative_state_lq[sectors_coloc],'Business',ax=ax[0])\n",
    "plot_colocation(creative_state_lq_emp[sectors_coloc],'Employment',ax=ax[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_co_location.pdf'.format(date=today_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_location_heatmap(lq_df,name_for_title,ax=ax):\n",
    "    '''\n",
    "    Function that creates a co-location heatmap taking a df with LQs by location (state) as input\n",
    "    \n",
    "    '''\n",
    "    #Create the correlation matrix with the input df\n",
    "    correlation_matrix = lq_df.corr()\n",
    "    \n",
    "    #Plot\n",
    "    im = ax.imshow(correlation_matrix,cmap='seismic',aspect='auto')\n",
    "    \n",
    "    #Colorbar\n",
    "    fig.colorbar(im,ax=ax)\n",
    "    \n",
    "    #Axes\n",
    "    ax.set_xticks(np.arange(len(correlation_matrix)))\n",
    "    ax.set_yticks(np.arange(len(correlation_matrix)))\n",
    "    \n",
    "    ax.set_ytickslabels(correlation_matrix.index)\n",
    "    ax.set_xtickslabels(correlation_matrix.index)\n",
    "    \n",
    "    ax.set_title('{name} co-location'.format(name=name_for_title))\n",
    "    return(ax)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact detail availability\n",
    "\n",
    "To conclude our initial exploration of DENUE data, we have a look at the availability of contact details for companies.\n",
    "\n",
    "* How many have addresses (we will simply count postcodes)\n",
    "* How many have telephones?\n",
    "* How many have email addresses?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import product to calculate the cartesian product of variables\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will create a reduced dataframe with the variables we are interested in: \n",
    "#(contact and company characteristics relevant for the survwt)\n",
    "\n",
    "#Select contact variables\n",
    "\n",
    "#Contact variables\n",
    "contact_vars = ['postcode','telephone','email','website']\n",
    "\n",
    "#Metadata for analysis\n",
    "metadata_vars = ['employee_sizeband','creative_sector','state']\n",
    "\n",
    "#Create reduced df\n",
    "contact_cis = cis[contact_vars+metadata_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many have postcode, telephone and email?\n",
    "\n",
    "contact_cis[contact_vars].apply(lambda x: x.isna()==False).mean()\n",
    "\n",
    "#We have postal addresses for everyone, telephone for 55% and email for 22%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This list comprehension creates a dict where the keys are the variables we are considering and the \n",
    "#values are the cross-tabs between each category and availability of contact details.\n",
    "# We don't consider postal addresses because those are available for almost everyone.\n",
    "\n",
    "cross_tabs = {x+'_'+y:pd.crosstab(contact_cis[x],contact_cis[y].isna()==False,normalize=0) for x,y in \n",
    "              product(metadata_vars,['telephone','email'])}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot contact details\n",
    "\n",
    "fig,ax = plt.subplots(nrows=3,ncols=2,figsize=(11,12),gridspec_kw={'height_ratios':[2,2,5]},sharex='col')\n",
    "\n",
    "#Go through the metadata variables we are interested in (eg sizeband, sector, state)    \n",
    "for num,x in enumerate(metadata_vars):\n",
    "    \n",
    "    #Select the right cross tabs\n",
    "    x = [v for k,v in cross_tabs.items() if x in k]\n",
    "    \n",
    "    #Loop over them\n",
    "    for ct in x:\n",
    "        #We make sure everything comes out in the right order by checking the name of the contact variable\n",
    "        \n",
    "        \n",
    "        #The telephone crosstabs will always be in the left column\n",
    "        if ct.columns.name=='telephone':\n",
    "            \n",
    "            #NB we are sorting the rows so that the places with most availability are at the top\n",
    "            ct.sort_values(True,ascending=True).iloc[:,[1,0]].plot.barh(ax=ax[num][0],stacked=True)\n",
    "                \n",
    "            #We add a vertical line in the 50%\n",
    "            ax[num][0].vlines(x=0.5,ymin=0,ymax=len(ct),linestyle=':')\n",
    "    \n",
    "        #The email crosstabs will always be in the right column\n",
    "        else:\n",
    "            ct.sort_values(True,ascending=True).iloc[:,[1,0]].plot.barh(ax=ax[num][1],stacked=True)\n",
    "            \n",
    "            ax[num][1].vlines(x=0.5,ymin=0,ymax=len(ct),linestyle=':')\n",
    "    \n",
    "#Thig layout    \n",
    "plt.tight_layout()\n",
    "\n",
    "#name\n",
    "fig.suptitle('Availability contact details by Company size / sector / State',y=1.02,size=18)\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_contact_details_summary'.format(date=today_str)),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We conclude with a couple of heatmaps\n",
    "contact_cis['has_telephone'] = contact_cis.telephone.isna()==False\n",
    "contact_cis['has_email'] = contact_cis.email.isna()==False\n",
    "\n",
    "\n",
    "contact_cross = [pd.pivot_table(\n",
    "    contact_cis.groupby(['creative_sector','state'])[x].mean().reset_index(drop=False),\n",
    "    index='creative_sector',columns='state',values=x) for x in ['has_telephone','has_email']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hm(ct,ax=ax):\n",
    "    '''\n",
    "    Takes a crosstab and returns a heatmap\n",
    "    \n",
    "    '''\n",
    "    #Extracts the sectors and states sorted\n",
    "    \n",
    "    sectors_contact_sorted = ct.mean(axis=1).sort_values(ascending=False).index\n",
    "    states_contact_sorted = ct.mean(axis=0).sort_values(ascending=False).index\n",
    "\n",
    "    #Plots\n",
    "    ims = ax.imshow(ct.loc[sectors_contact_sorted,states_contact_sorted],cmap='seismic',aspect='auto',\n",
    "                   vmax=1,vmin=0)\n",
    "\n",
    "    #Creates the axis labels \n",
    "    ax.set_yticks(np.arange(len(ct.index)))\n",
    "    ax.set_yticklabels(sectors_contact_sorted,size=12)\n",
    "    ax.set_xticks(np.arange(len(ct.columns)))\n",
    "    ax.set_xticklabels(states_contact_sorted,rotation=45,ha='right',size=12)\n",
    "    \n",
    "    #Draw the color bar\n",
    "    fig.colorbar(ims,ax=ax)\n",
    "\n",
    "    return(ims)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,9),nrows=2)\n",
    "\n",
    "make_hm(contact_cross[0],ax=ax[0])\n",
    "make_hm(contact_cross[1],ax=ax[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "ax[0].set_title('Contact availability: Telephone by state and sector',size=14)\n",
    "ax[1].set_title('Contact availability: Email by state and sector',size=14)\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(fig_dir,'{date}_state_sector_availability.pdf'.format(date=today_str)),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And what about the websites?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_cis['has_website'] =contact_cis['website'].isna()==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "\n",
    "pd.pivot_table(\n",
    "    contact_cis.groupby(\n",
    "        ['creative_sector','employee_sizeband'])['has_website'].mean().reset_index(drop=False),\n",
    "    index='creative_sector',columns='employee_sizeband',\n",
    "    values='has_website').T.loc[sizeb_sorted,:].plot.bar(ax=ax,width=0.8,title='Website availability by sector & size')\n",
    "\n",
    "ax.legend(ncol=2)\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
